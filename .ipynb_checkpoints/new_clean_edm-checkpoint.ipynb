{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c798b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85219f1e",
   "metadata": {},
   "source": [
    "<b>Data Merging</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66753cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df_ableton = pd.read_csv('ableton_data_18nov2022.csv', low_memory=False)\n",
    "df_flstudio = pd.read_csv('flstudio_data_18nov2022.csv', low_memory=False)\n",
    "\n",
    "#Combined Data and assign 1 = ableton and 0 = flstudio to differentiate the source\n",
    "df_ableton[\"label\"] = 1\n",
    "df_ableton = df_ableton[['label','title','selftext']]\n",
    "df_flstudio[\"label\"] = 0\n",
    "df_flstudio = df_flstudio[['label','title','selftext']]\n",
    "df_main = pd.concat([df_ableton, df_flstudio])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86c4927d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">title</th>\n",
       "      <th colspan=\"4\" halign=\"left\">selftext</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8738</td>\n",
       "      <td>8633</td>\n",
       "      <td>Help</td>\n",
       "      <td>9</td>\n",
       "      <td>8738</td>\n",
       "      <td>8738</td>\n",
       "      <td>Curious to see how long users have had with th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8958</td>\n",
       "      <td>8912</td>\n",
       "      <td>What did you make in Live this week? / Feedbac...</td>\n",
       "      <td>5</td>\n",
       "      <td>8958</td>\n",
       "      <td>8958</td>\n",
       "      <td>Hi everyone, the first thing is that I'm Spani...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      title                                                                 \\\n",
       "      count unique                                                top freq   \n",
       "label                                                                        \n",
       "0      8738   8633                                               Help    9   \n",
       "1      8958   8912  What did you make in Live this week? / Feedbac...    5   \n",
       "\n",
       "      selftext                                                                 \n",
       "         count unique                                                top freq  \n",
       "label                                                                          \n",
       "0         8738   8738  Curious to see how long users have had with th...    1  \n",
       "1         8958   8958  Hi everyone, the first thing is that I'm Spani...    1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtained a raw data of 8,958 from ableton and 8,738 from flstudio\n",
    "df_main.groupby(['label']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbcd25d",
   "metadata": {},
   "source": [
    "<b>Defining Functions for Cleaning</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a1ae89a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to clean text\n",
    "\n",
    "df_cleaning_text = pd.read_csv('cleaning_text.csv', low_memory=False)\n",
    "\n",
    "def cleaning_text(text):\n",
    "    for i in range(df_cleaning_text.shape[0]):\n",
    "        text = text.replace(str(df_cleaning_text.word[i]),str(df_cleaning_text.replacement[i]))\n",
    "        \n",
    "        text = re.sub(r'http\\S+', '', text) #remove URL\n",
    "    \n",
    "    if text == '[removed]': #replace [removed] as blank\n",
    "        text = np.nan\n",
    "        \n",
    "    if text == 'nan':\n",
    "        text = np.nan\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "92ef93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to clean spelling\n",
    "\n",
    "df_cleaning_word = pd.read_csv('cleaning_word.csv', low_memory=False)\n",
    "\n",
    "def cleaning_word(text):\n",
    "    for i in range(df_cleaning_word.shape[0]):\n",
    "              \n",
    "        text = text.replace(\" \" + str(df_cleaning_word.word[i]) + \" \",\n",
    "                            \" \" + str(df_cleaning_word.replacement[i]) + \" \")\n",
    "          \n",
    "    if text == '[removed]': #replace [removed] as blank\n",
    "        text = np.nan\n",
    "        \n",
    "    if text == 'nan':\n",
    "        text = np.nan\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a087b12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to combine terms\n",
    "\n",
    "df_cleaning_terms = pd.read_csv('cleaning_terms.csv', low_memory=False)\n",
    "\n",
    "def cleaning_terms(text):\n",
    "    for i in range(df_cleaning_terms.shape[0]):\n",
    "              \n",
    "        text = text.replace(\" \" + str(df_cleaning_terms.word[i]) + \" \",\n",
    "                            \" \" + str(df_cleaning_terms.replacement[i]) + \" \")\n",
    "          \n",
    "    if text == '[removed]': #replace [removed] as blank\n",
    "        text = np.nan\n",
    "        \n",
    "    if text == 'nan':\n",
    "        text = np.nan\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "41a186e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function for lemmazization\n",
    "\n",
    "def lemmatize_text(text):  \n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    try:\n",
    "        text = ' '.join([lemmatizer.lemmatize(w) for w in tokenizer.tokenize(text)])\n",
    "    \n",
    "    except:\n",
    "        print('error')\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "63ff22c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'being', 'don', 'myself', \"that'll\", 'a', 'we', 'how', 'do', \"don't\", \"won't\", 'above', 'she', \"you'll\", \"wouldn't\", 'our', 'these', 'they', 'weren', 'down', 'needn', 'with', 'hers', 'been', 'were', 'such', \"weren't\", 'while', 'all', 'aren', 'an', 'through', 'when', 'those', 'then', 'own', \"doesn't\", 'this', \"should've\", 'me', 'further', 'did', 'just', 'under', 'at', 'his', \"hadn't\", \"mightn't\", 'of', 'shouldn', \"you've\", 'am', 'itself', 'hasn', \"needn't\", \"aren't\", \"shan't\", 'won', 'its', 'herself', 'didn', 'because', 'are', 'doesn', 'during', 'y', 'should', 'be', 'yourself', 'on', \"couldn't\", \"isn't\", 'haven', 'between', 'what', 'from', 'couldn', 'why', 'isn', 'or', 'most', 'until', \"you'd\", 'too', 'once', 'you', 'as', 'about', 'o', 'the', 'before', 'again', 'against', 'their', 'no', \"haven't\", 'had', 'now', 't', 've', 'very', 'yourselves', \"hasn't\", 'd', 'not', 'over', 'was', 'for', 're', 'himself', 'few', 'mustn', 'themselves', 'wouldn', 'out', 'wasn', 'them', 'both', 'some', 'ma', 'that', \"it's\", 'can', \"wasn't\", 'my', 'mightn', 'each', 'him', 'who', \"she's\", \"shouldn't\", 'nor', 'does', 'have', 'same', 'into', 'in', 'hadn', 'shan', 'but', 'whom', 'll', 'up', 'only', 'more', 'ain', 'ours', 'it', 'any', 'which', 'other', 'is', 'doing', 'will', \"didn't\", 'to', 'by', 'there', \"you're\", 'theirs', 'where', 'off', 'm', 'below', 'so', 'than', 's', \"mustn't\", 'if', 'he', 'after', 'yours', 'your', 'here', 'has', 'and', 'ourselves', 'having', 'her', 'i'}\n"
     ]
    }
   ],
   "source": [
    "#checking on stop words\n",
    "stop = set(stopwords.words('english'))\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af60bc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include new stop words\n",
    "new_stops = {\"i'm\", \"we've\", \"hi\", \"doe\", \"doesn't\"}\n",
    "stop.update(new_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4a866621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to remove stop words\n",
    "\n",
    "def remove_stop(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    word_tokens = tokenizer.tokenize(text)\n",
    "    for i in word_tokens:\n",
    "            no_stop = ' '.join([w for w in word_tokens if not w.lower() in stop])          \n",
    "    try:       \n",
    "        return no_stop\n",
    "    except:\n",
    "        return np.nan #there are title with a blank characters (\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c0dc8c",
   "metadata": {},
   "source": [
    "<b>Apply Cleaning</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8e609160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterative process for continuous cleaning data (so as not to rerun past edits)\n",
    "df_main = pd.read_csv('clean_data.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "94591b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initate new column 'cleantext' and cleantitle\n",
    "df_main['cleantext'] = df_main['selftext'].apply(cleaning_text)\n",
    "df_main['cleantitle'] = df_main['title'].apply(cleaning_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6ea08e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to string\n",
    "df_main[\"selftext\"] = df_main[\"selftext\"].astype('string')\n",
    "df_main[\"title\"] = df_main[\"title\"].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5cb401b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates\n",
    "df_main = df_main.drop_duplicates(subset='selftext', keep=\"first\")\n",
    "df_main = df_main.drop_duplicates(subset='title', keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1c963c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set text to lowercase\n",
    "df_main['cleantext'] = df_main['cleantext'].str.lower()\n",
    "df_main['cleantitle'] = df_main['cleantitle'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "16bd4842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop text with less than 20 words\n",
    "df_main['wordcount'] = [len(re.findall(r'\\w+', str(i))) for i in df_main['cleantext']]\n",
    "df_main = df_main.drop(df_main[df_main.wordcount < 20].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5530d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#customised processing of cleaning words e.g. spelling\n",
    "df_main['cleantext'] = df_main['cleantext'].apply(cleaning_word)\n",
    "df_main['cleantitle'] = df_main['cleantitle'].apply(cleaning_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3ca55d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#customised processing of combining terms\n",
    "df_main['cleantext'] = df_main['cleantext'].apply(cleaning_terms)\n",
    "df_main['cleantitle'] = df_main['cleantitle'].apply(cleaning_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "970292e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization\n",
    "df_main['cleantext'] = df_main['cleantext'].apply(lemmatize_text)\n",
    "df_main['cleantitle'] = df_main['cleantitle'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6bc41200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words\n",
    "df_main[\"cleantext\"] = df_main.cleantext.apply(remove_stop)\n",
    "df_main[\"cleantitle\"] = df_main.cleantitle.apply(remove_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "599f151c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">wordcount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8272.0</td>\n",
       "      <td>78.505319</td>\n",
       "      <td>87.612766</td>\n",
       "      <td>20.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>3749.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8635.0</td>\n",
       "      <td>94.516503</td>\n",
       "      <td>93.229845</td>\n",
       "      <td>20.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>3868.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      wordcount                                                       \n",
       "          count       mean        std   min   25%   50%    75%     max\n",
       "label                                                                 \n",
       "0        8272.0  78.505319  87.612766  20.0  38.0  59.0   92.0  3749.0\n",
       "1        8635.0  94.516503  93.229845  20.0  46.0  73.0  114.0  3868.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary of clean data\n",
    "df_main.groupby(['label']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6cec63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main[\"cleantext\"] = df_main[\"cleantext\"].astype('string')\n",
    "df_main[\"cleantitle\"] = df_main[\"cleantitle\"].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "76030eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main[\"combinedtext\"] = df_main[\"cleantext\"].map(str) + \" \" + df_main[\"cleantitle\"].map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06392fd9",
   "metadata": {},
   "source": [
    "<b>Generate Word Count List</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "569a61b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = df_main.combinedtext.values.tolist()\n",
    "word_list = []\n",
    "for item in text_list:\n",
    "    breakdown_words = word_tokenize(item)\n",
    "    for word in breakdown_words:\n",
    "        word_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cabe1e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22759"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate list of unique words\n",
    "wordset = set(word_list)\n",
    "unique_list = list(wordset)\n",
    "len(unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fa74fbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 words completed\n",
      "10000 words completed\n",
      "15000 words completed\n",
      "20000 words completed\n"
     ]
    }
   ],
   "source": [
    "#generate count for each unique word\n",
    "unique_count = []\n",
    "process_count = 0\n",
    "for x in unique_list:\n",
    "    count = 0\n",
    "    process_count += 1\n",
    "    for y in word_list:\n",
    "        if x == y:\n",
    "            count += 1\n",
    "    unique_count.append(count)\n",
    "    if(process_count % 5000 == 0):\n",
    "        print(str(process_count) + \" words completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dbb76906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word = pd.DataFrame(list(zip(unique_list, unique_count)), columns =['word', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "59a98fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export word list for manual data cleaning referencce\n",
    "df_word.to_csv(r'word_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9618ab07",
   "metadata": {},
   "source": [
    "<b>Export Data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6c1bf553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export data\n",
    "df_main.to_csv(r'clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1289289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
